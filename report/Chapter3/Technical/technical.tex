%!TEX root = ../../report.tex
\section{Technical}

% 0.5 page

\todo{beskriv approach for at embedded values i et system: definer stakeholders, definer pros/cons for stakeholders, definer values ud far pros/cons}
In this section, a focus will be on the actual domain where the system is to be designed and the technological choices taken for the systems. This will be done with the chosen values from the conceptual section in mind. 
The section are divided in to two parts. The first will be an analysis, whereas the second will focus upon the implementation and challenges for doing so. 
A recommender system can be seen in many forms and be found many places, as described in chapter \ref{chap:chapter1}. For this report, a recommender system for courses at the IT University, will be conceived. The reason for this, is that all full-time students are faced with one or more options for non-mandatory courses throughout their education. This can, for some students, be hard to do, because of the many courses available as well as the lack of transparency of the content for each of these courses.\\

The intuition for the system can be divided in to three basic step. The first is some sort of data extraction from the systems at ITU, that holds the data needed to make a recommendation. The second step is to prioritize this data and select only the relevant. The third step is to process the selected data and transform this into some sort of structure holding students and courses and thereby constructing the recommendations.

% 1-2 page
\subsection{Design Choices}
In this section explanations of the design choices made throughout the design process will be presented as well as the 'consequences' of choosing the different solutions. 
\subsubsection*{Collaborative or Content}
One of the first and most important choices made for this system, is what kind of recommendation type of system that should be used. In section \ref{chap:chapter1} we outlined three different types of recommender systems: Collaborative-filtering (CF), Content-based (CT) and Hybrid approaches. As also explained in \ref{sec:hybrid} it is most common to use a hybrid of the two. To keep the system as simple as possible for a start, the approach chosen is the content-based one. The reasons for this, will be outlined below. \\
The CF approach mostly builds upon ratings from users, which is used to either compare users with users or items with items, and then produce a list of recommendations. This makes the ratings a central and crucial part of the system. In order to implement this approach for a ITU recommender systems, these ratings could come from the course evaluation, which basically asks the students to 'rate' and comment on both the course and teacher. This could definitely be a viable solution, except that it relies a great deal upon the data from the course evaluation. Unfortunately the evaluation is only done by around 35-40\% of all students, which means the system will be affected of the things described as the 'Data sparsity' problem in section \ref{subsec:collaborativeAdvantages}. Even though many recommender systems suffer from this problems \todo{kilde?}, and are still used, the other approach have been chosen.\newline 
Another problem would be the reliability of the ratings. Even though these would come from the students, and thereby represent their opinion about the courses, the would properly more reflect how popular are course are, more than the actual content of each course.\\ 
The primary reason for choosing the CT approach is the availability of keyword for each course. Each of the courses available for the students, has an associated course description, which will be the primary source of content. In contrast to the CF approach, using the keywords from the course description, instead of ratings, would represent what the teacher thinks and imagines about the course, which is a more authentic and representative source of information in our opinion. 


\subsubsection{Persistent or memory?}
\label{subsec:persistent}
As part of the design process, it is necessary to look at the usage of the system, in order to choose if data should be read into memory at run-time when needed or a more persistent choice of data storage is needed. The answer to a question like this is closely related to when and how often the system is running. If the recommendations are needed many times daily or weekly, the choice would be to have the system running on a server, with a database taking routines backup of things like the different users profiles and recommendations. If the the system only would run a couple of times a month or year, one option would be to load all the raw data into the system for each run. Even if this process would be expensive to perform, it is easy to argument this being okay, since the data would only be used a few times and could be loaded in before actually needing it. Another option would be to load the raw data into the system on the first run, stripping it for unnecessary information and then storing this data in a database and then just only update this database with new data, before each run. This latter option have been the chosen solution, since it enables the system to spend less time reprofiling all students for each run. It is only necessary to profile new students and courses. This should in theory reduce the time needed to calculating the recommendations.

NOTES:
even though the program only will run 2-3 times per year, persistent the data to a database is needed. One could simply keep the data in memory, but then it would be needed to 'reprofile' all students and analyze the content for each course, for each run of the program. When persisting the data, the program 'only' needs to compare the new data with the previous created profiles and the content for the courses.


Target group?
Tidsplan?
% 0.5-1 page
%\subsection{Data Modeling}
%Following the section \ref{subsec:persistent} a analysis of the data for ITU, including information about students and courses, was needed. This analysis are then devised into a model of data, which we have chosen to represent using a ER-diagram. This is useful for further discussions and improvement of the system, but can also serve as inspiration for the classes and objects needed at the programmatic abstraction layer. 

%\subsubsection{ER-Diagram}
%The ER-diagram following below reflects our considerations and reflections about how to represent the selected data in relational database. At the time of writing, where no real implementation has taken place, this diagram reflects the bare minimum required for the development of the system. The reason for not including the rest, is that this is best done with a agile and iterative development process, which have not been possible to engage in due to a time-constraint. It represents the results of the data selection process, which have been about prioritizing the available data from ITU in to the relevant data for the system, which have meant we have excluded some non-needed information attributes.

% \begin{figure}[H]
% \centering
% \includegraphics[scale=0.5]{Pictures/ER-Diagram.jpg}
% \label{ER-diagram}
% \caption{ER-Diagram}
% \end{figure}

% 0.5-1 page
\subsection{Architecture Analysis}
In order to give the reader an overview of the program, this section will present an overview of the components involved in the system and outline the flow of the program. The diagram below displays a view of the system with components: 

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{Pictures/Architecture-Diagram.jpg}
\label{Architecture-Diagram}
\caption{Architecture-Diagram}
\end{figure}


To the left the black box of ITU are displayed. This represents the data source, that will be used in order to produce the recommendations. The data will consists of all information about students and courses. The Data Processor component will receive all this data and sort it out, keeping only the relevant information. The data will then be split among the Content Analyzer and the Profile Learner, which will construct data structures of courses and students, as explained below. The Filtering Component will then receive these structure and output the lists of recommendations for each students. 


% % ? page
% \subsection{Glossary}
% \label{glossary}
% \begin{itemize}
% 	\item[ECTS points]
% 	\item[SWU]
% 	\item[GBI]
% 	\item[CF] Collaborative-Filtering approach
% 	\item[CT] Content-based approach
% 	\item[Course evaluation]
% \end{itemize}
% 1-2 page
\subsection{ITU Recommender System}
So far the previous sections have described the domain and the surrounding parts of the actual system. In this section, we will go in to depth with the actual recommender system and its individual components. The responsibility as well as the input and output will be described for each components. The order of this section follows the flow of the program and will therefore start med the Content Analyzer.
\subsubsection{Content analyzer}
This component are responsible for analyzing all courses available at ITU and construct a vector for each of these courses. The input of courses, will come from the Data Processing \todo{Describe Data processor} and the output will be a in some sort of abstract data type, possibly like a map. The process of producing the vectors are expressed as the pseudo algorithm below:
\begin{itemize}
	\item Make a list of non-keywords like "this", "and", "is" or "will". (\todo{NOTE}: This will cause the system to be less biased (fairness?), compared to a human (Rune) selecting the keywords.)
	\item Construct a string parser which identifies all words in the current document and applies a hash-function on each of these words, except the ones from the non-keyword list
	\item Count number of occurrences of each word found by the string parser.
	\item Repeat step 2 and 3 for all courses and construct a data structure of maps with maps. The first map has the course code as key and the value being a map containing each specific keyword and key and the number of occurrences as value. 
	\item Use the TFIDF \todo{Ref to TDIFD formula} formula for each course, which will produce a vector space containing n-keywords dimensions, where each dimension contains a vector with a length representing the weight of this keyword, for this specific course 
	\item Use the Cosine normalization formula for normalizing every keyword vector for all courses.
\end{itemize}
At the end of this algorithm, each course will have an associated vector, which represents the value, in relation to keywords, of the course compared to all other courses. The resulting data structure, will then be used by the Filtering Component and the Profile Learner, which will be described below.

\subsubsection{Profile Learner}
This component is used to analyze every student preferences. To do this, some feedback or history from the students are needed. This feedback will, as explained \todo{where is it explained?}, come from the previous elective courses, that the student have been signed up for. The reason for using this information, is the fact, that we believe that this is the most significant and reliable source of information. Like the Content Analyzer, the flow of this component are expressed in form of a pseudo algorithm outlined below:
\begin{itemize}
	\item Retrieve all elective courses the student have been signed up for, from the Content Analyzer.
	\item Of these courses, compute the average vector (adding the vectors together and divide by number of vectors) by projecting each of the vectors on each other. This resulting vector represents the users preferences, in relation to the elective courses the student have signed up for. 
\end{itemize}
This will 'collect' all the elective courses the student have been signed up for and produce a resulting vector, which expresses the students preferences towards courses he or she may like. If the student have had no elective courses, the Profile Learner will notify the Filtering Component and this will decide how to proceed. 

\subsubsection{Filtering Component}
This component receive the results from the Content Analyzer and the Profile Learner, in order to produce the list of recommendations for each student. The input needed, are the courses with an associated keyword vector and a vector representing the preferences for each student, based on previous elective courses. For new students this information will not exists. In this case a the filtering component will produce a list of random courses, but only out of those courses, that are 'relevant for'(which is a tag placed on each course) the student. When the student have had elective courses the component generates the list of recommendations like described below:
\begin{itemize}
	\item In the list of courses taken from the Content Analyzer, sort out all the courses the student already have been signed up for. (the student are not allowed to sign up for courses, he or she already have been signed up for - \todo{VALUE-NOTE-->}This makes the system a bit bias, since the student could have been signed up for a courses, but failed it. Cases like this, will be ignored by the system. If a student have failed a course, the student will know if he or she wants it again, which will be hard to know for the system)
	\item In the list of courses taken from Content Analyzer, sort out all courses that the student will have as mandatory courses in the future.
	\item Use the resulting vector produced in step 2, to compare every course from the Content Analyzer to produce the list of recommendations.
	\item Sort the list of recommendations, having the courses with the most similarity (closest to 1) with the resulting vector 
\end{itemize}
The output of this component will be a list of recommendations sorted after the courses who's result vector is the most similar to the vector representing each student preferences, according to the cosine similarity formula \todo{ref til cosine formula}. This list will then be shorted down to an appropriate length with courses and sent out to email to the student. 

% \subsubsection{Data on students}
% First step is to divide up the students into the groups where they belong, using the first five student data points.

% - Education
% - Track
% - Semester (Bachelor students can only choose an elective course on 4th and 5th semester) (Masters students can choose an elective course on each semester (4th is only their thesis))
% - ECTS points earned
% - Nationality

% Only when the students have been divided up into groups is where the recommender system will go to work. By analyzing the next student data points the RS will recommend elective courses to the students in question.

% (which courses has the student already had, (DO NOT TAKE COURSE AND EXAM DATES INTO CONSIDERATION (AMAZON DOES NOT DECIDE WHETHER SOMETHING IS TOO EXPENSIVE FOR ME OR WHETHER I NEED THAT, THAT IS UP TO THE INDIVIDUAL TO DECIDE, THE SAME APPLIES HERE)))

% - Grades (only in relation to elective courses?)
% - Previous grades (all courses are available to all students that meets the formal requirements) (just because you get a low grade on a previous course does not necessarily makes that person less interested in a course where that previous course is a pre-requisite)
% - Previous courses (mandatory) and projects
% - Previous elective courses (could be a sign of interest)
% - Age (when you have been accepted to ITU you are in and can freely choose which courses you wish to attend no matter of age - we do not want to implement any bias into the system)
% - Current courses (to make sure that the recommended elective course is not time wise placed on top of on of the mandatory courses)

% The last two student data point serves as contact information (name is also used to refer to the above mentioned data points).
 
% - Name
% - Mail
% - 

% \subsubsection{Course information}

% - Name
% - ECTS (should be included, so a student with only 7,5 etcs available, will not be recommended courses with 15 etcs)
% - Which semester
% - Course code
% - Course language
% - Max seats
% - Current number of taken seats
% - Formal requirements (to vaguely defined in order to extract proper information)
% - Course learning goals (not important)
% - Academic content (this is here the keywords are extracted for the recommender system)
% - Mandatory activities (not important)
% - Exam forms (date and description) (the student must check if exam dates collide)
% - Literature (not important)
% - Curriculum (not important)
% - Course responsible/manager (not important)
% - Relevant for (needs to properly defined, but is useful)
% - Time and place (it is the students responsible to check if courses collide)



% \subsubsection{List of Requirements}
% \begin{itemize}
% 	\item The list of possible courses for each student, must NOT contain mandatory courses or courses the student already have had.
% 	\item Der skelnes mellem tilmeldte og tidligere tilmeldte kurser, i forhold til bestået kurser, for at undgå at man bliver anbefalet kurser, som man er igang med på tidspunktet hvor anbefalingen falder. 
% \end{itemize}
  

% \subsubsection{Recommender system output}

% - Max seats in recommended course
% - Current number of seats taken in recommended course
% - NOTE: please check that the recommended courses are not colliding with your mandatory or other elective courses
% - 




% FIND INFORMATION THAT DESCRIBES HOW A CONTENT ANALYZER, PROFILE LEARNER AND FILTERING COMPONENT ARE 

% MAKE NEW DRAWING SHOWING THE INFORMATION FLOW WITHIN THE SYSTEM BOTH FOR CONTENT-BASED AND COLLABORATIVE



% IF COLLABORATIVE BASED (ALWAYS RATING BASED): USER-USER OR ITEM-ITEM

% It will be a choice between what the course contain (can't really be shown from the users ratings of the course, since two courses can be completely different in regard to content, but have the same overall ratings) and how popular the course is (can be shown by the ratings, but will be a problem with new courses). Only about 40 percent of students are rating their courses via the course evaluation.


\newpage

