\section{Technology And Biases}Our present days society is vastly build on communication and is connected via thousands upon thousands of separate technical systems, each performing their individual tasks in order for the whole to properly function. There can be a lot of laws and restrictions associated with developing and building a new software system, and these laws and restrictions will undoubtedly show themselves in a variety of degrees as the system is used across international borders and continents. But if we put aside all the juristidictional aspects of a development process, we have another very important aspect that can be of a great deal of influence on the development as well as the use of software systems: biases. Biases can find their way into software systems in several ways and can be seen in many different forms. In this chapter we will try to give our definition of what a bias in technology is, which kind of biases we most often see, and which implications these biases can have on the development process as well as the overall use of the system.In order for us to correctly proceed with this study, we will first have to come up with a definition and explanation of what exactly a bias is.\subsection{How to deal with biases in technical systems}In order to ensure that a systems functionality, be it technical as well as philosophical, will not suffer from an imminent threat of biases, it is of critical importance to discover and deal with biases as early on in the development process as possible. This will give the possibility to limit the impact of the bias in question to as little as possible.emphasis on changing the “common” way systems are built, where biases are found and dealt with after the system has been developed, and instead working towards a mentality where we see the elimination of biases in software systems as an integrated part of the development process. \subsection{Framework for finding existing biases in technical systems.}\subsubsection{Categories of biases in technical systems}In order for us to find the biases we will first need to take a look at the different categories of biases that occur in technical systems.\begin{itemize}	\item Pre-existingA pre-existing bias describes a bias that in relation to the system exist by itself and in general before the system is created. A pre-existing bias can evolve from several different places, some of them being society as a whole, subcultures within the society, or via private or public institutions and organizations. They can furthermore be a reflection of personal biases and opinions from people closely related to the design process of the system, here putting a high emhasis on the client and system designer.As mentioned, there are several areas from which a pre-existing bias can arise, and an important thing to remember is, that these can show themselves via a conscious effort from the people involved in the decision making process behind the system, but equally as well be integrated on an unconscious level, even when the system designers are trying their best to conciously avoid doing so (refer to the development of the game for boys, girls, and boys/girls respectively).	\item TechnicalA technical bias describes a bias that is formed when the system designers are trying to resolve technical constraints or implement specific considerations. These biases can occur in relation to both hardware and software. Hardware-wise the biases are most likely getting fewer and fewer, mainly due to responsive webpages that throws away the need for specific monitor sizes and alike and at the same time giving the option of accessing property via alternative access devices such as tablets and smartphones. Software wise the biases can occur in a variety of ways. This includes algorithms that does not uphold a level of fairness to all users under all circumstances. This can be an algorithm that is used in the wrong context, for example if the system is designed to perform a specific task, and then at some point is used to solve a different kind of task. On the surface it might look like the system is solving the assignment without any issues or implications, but underneath there could very well be some biases that would question the reliability of the system.Another way biases can arise in the context of software is when the designers are trying to implement a certain decision making part into the system that does not take human interpretation into context, but instead relies on a set of predefined formulas. This can possibly create some situations in which not everyone the system affects are treated in a fairly manner.	\item EmergentAn emergent bias can only arise in the context of use of the system containing the bias. The emergent bias most often shows itself a great deal of time after a design has been made, and can be due to a change in the values regarding the system in question or another form of change in the users who utilizes the system. One place that seems to be prone to emergent biases is in the systems where user interfaces play a vital role. User interfaces are most often designed for a specific set of users. This could potentially create difficulties for a new set of users in the case that the system where eventually used in a different context, since they might not grasp the system functionality in the same way as the originally intended users can, thus creating an emergent bias in the system. \end{itemize}

\subsubsection{Description and functionality of the framework}

\subsubsection{How to apply the framework on technical systems}
\subsection{The implications of biases from a technical, political, and ethical point of view}If a bias-containing system becomes a standard in its field, the bias will become pervasive within its area, hence spreading and increasing its impact. This can in some cases have a profound impact seen from a technical, political, and ethical perspective. An example of this can be when a search based recommender system is set up to only give recommendations based on a users previously searches or interests. If the user in question tries to search for a specific political subject, the recommender system will here only give recommendations that are closely related to the users political interests. When this occurs, the user can possibly be mislead to believe that his or her own political convictions are omnipresent throughout society since the search based recommender system make it look like this point of view is the only one that exists. This can further make it harder for people to initiate in a debate since they in some way are “shown” that their opinions and meanings are the same ones shared by everyone else.